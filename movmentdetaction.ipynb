{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import ImageGrab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_detector():\n",
    "  \n",
    "  frame_count = 0\n",
    "  previous_frame = None\n",
    "  cap = cv2.VideoCapture(0)\n",
    "  \n",
    "  \n",
    "  while True:\n",
    "    frame_count += 1\n",
    "\n",
    "    # 1. Load image; convert to RGB\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (50,50))\n",
    "    img_rgb = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if ((frame_count % 2) == 0):\n",
    "\n",
    "      # 2. Prepare image; grayscale and blur\n",
    "      prepared_frame = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n",
    "      prepared_frame = cv2.GaussianBlur(src=prepared_frame, ksize=(5,5), sigmaX=0)\n",
    "      \n",
    "      # 3. Set previous frame and continue if there is None\n",
    "      if (previous_frame is None):\n",
    "        # First frame; there is no previous one yet\n",
    "        previous_frame = prepared_frame\n",
    "        continue\n",
    "      \n",
    "      # calculate difference and update previous frame\n",
    "      diff_frame = cv2.absdiff(src1=previous_frame, src2=prepared_frame)\n",
    "      previous_frame = prepared_frame\n",
    "\n",
    "      # 4. Dilute the image a bit to make differences more seeable; more suitable for contour detection\n",
    "      # kernel = np.ones((5, 5))\n",
    "      # diff_frame = cv2.dilate(diff_frame, kernel, 1)\n",
    "\n",
    "      # 5. Only take different areas that are different enough (>20 / 255)\n",
    "      thresh_frame = cv2.threshold(src=diff_frame, thresh=20, maxval=255, type=cv2.THRESH_BINARY)[1]\n",
    "\n",
    "      con = np.concatenate((prepared_frame, thresh_frame), axis=1)\n",
    "      cv2.imshow('Movment', con)\n",
    "\n",
    "      # contours, _ = cv2.findContours(image=thresh_frame, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "      # cv2.drawContours(image=img_rgb, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if (cv2.waitKey(30) == 27):\n",
    "      cap.release()\n",
    "      cv2.destroyAllWindows()\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "motion_detector()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1627bc85717b7560124dd1e075a8d774e00c2964086061d93c5aa15f3672a689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
